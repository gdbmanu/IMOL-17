\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2018

% ready for submission
\usepackage{nips_2018}

% to compile a preprint version, e.g., for submission to arXiv, add
% add the [preprint] option:
% \usepackage[preprint]{nips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2018}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[usenames,dvipsnames]{color}
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage[pdftex]{graphicx} 

\usepackage{algorithm}
\usepackage{algorithmic}
% Attempt to make hyperref and algorithmic work together better:
%\newcommand{\theHalgorithm}{\arabic{algorithm}}

%\title{Optimal scene decoding with foveal computation: a variational perspective}
\title{Variational information maximizing control: a unifying view}
% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Emmanuel Daucé\\
  Ecole Centrale de Marseille,\\ 
  Aix Marseille Univ, Inserm,\\ 
  INS, Institut de Neurosciences des Systèmes, \\
  Marseille, France\\
  \texttt{emmanuel.dauce@centrale-marseille.fr} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
  The abstract paragraph should be indented \nicefrac{1}{2}~inch
  (3~picas) on both the left- and right-hand margins. Use 10~point
  type, with a vertical spacing (leading) of 11~points.  The word
  \textbf{Abstract} must be centered, bold, and in point size 12. Two
  line spaces precede the abstract. The abstract must be limited to
  one paragraph.
\end{abstract}

\section{Motivation}

Though ubiquitous in biology, object recognition through saccades is seldom considered in artificial vision. The reasons are many, of which the existence of highly effective sensors capable to provide millions of pixels at low cost. %\footnote{in contrast with animals retina whose actual design relies on a long optimization process under severe resource constraints.}.
In counterpart, increasingly powerful computing devices are needed to compute in parallel those millions of pixels to perform recognition, consuming resources in a brute-force fashion. 
The example of animal vision encourages however a different approach towards more parsimonious recognition algorithms. A salient aspect of animal vision is indeed the use of \emph{active} sensing devices, capable of moving around within some degrees of freedom in order to choose a particular viewpoint. The important redundancy present in the {\color{blue} visual/sensory} data was exploited by natural selection,  ending up in energy-efficient visual exploration policies, exploiting only little portions of the visual environment to decode the total sensory scene.

The opportunity to neglect large parts of the {\color{blue} visual/sensory} scene should thus be considered when the energy is scarce, as it is the case for drones and robots. 
%that need to react fast with light and low-power sensing devices. 
It is also relevant in computer vision, where Mega-pixel images appeals for selective convolutions, in order to avoid unnecessary matrix products. 
%A computer vision program should for instance look back from past experience to see which viewpoint to use to provide the most useful information about a scene. 
Selecting the relevant pixels across time may then be a part of computer vision algorithms, in combination with traditional pixel-based computations. 

The idea of viewpoints selection turns out to consider beforehand the pixels that need to be processed to achieve the scene decoding. The general principle is that of
choosing the viewpoint that is the most {\color{blue} informative} \emph{in expectation}. This entails \emph{predicting the future {\color{blue} information gain}} made by choosing a given viewpoint over the total scene. Two parallel research tracks adopted and refined this very idea over the last twenty years. A first track, developed in robotics and control, insists on the formal contribution of action in the encoding the sensory field. This resorts to consider action as a \emph{code} that is later on revealed (decoded) by sensing the effect of action at the visual field \citep{klyubin2005empowerment,tishby2011information}. As such it may be optimized so as to maximize the code effectiveness, allowing to improve both the policy and the data model in the course of learning \citep{schmidhuber2007simple,mohamed2015variational,houthooft2016vime}. Another line of research, initially developed in human visual search modeling, considers action as a \emph{sample} (or viewpoint) over an underlying (covert) sensory scene. Then appropriate viewpoints should be selected to maximize the \emph{decoding accuracy}, that resorts to refine the beliefs about the underlying scene to reduce the posterior entropy (see \cite{najemnik2005optimal,najemnik2009simple,butko2010infomax,friston2012perceptions}).
  
This interestingly conducts to develop different objective functions that do not appear mutually compatible in a first place. The encoding efficacy objective encourages actions that provide informationally-rich content, which is formally defined as the information gain provided by improving prediction after taking action, also known as the ``surprise'' \cite{itti2005bayesian}. This first approach may be referred as the ``innovation-based'' approach to action selection. In contrast, the decoding accuracy objective encourage actions that provide a consistent belief update, measured at the log likelihood of the data after sampling. This implies to avoid surprising data and prefer actions that provide a sensory input that is consistent with the initial guess \cite{friston2010free}. This second approach may be referred as the ``conservation-based'' approach to action selection.  

We show here the two objectives can be reconciled when considering action as being both a code and a sample. This is done through postulating a bijection between the motor command and the actuator state.
%, resting on an \emph{inverse control} principle.
%, also known as the end-effector or ``ballistic'' control {\color{blue}[REFS]}. 
In that setup, the current observation is the decoding of a \emph{mixed code} (or compositional code {\color{blue}[REFS]}) made of a controlled code (i.e. the actuator state) and an uncontrolled code (i.e. the rest of the environment).


%Less intuitively, the ever-growing  learning databases used in machine learning also suggest an intelligent scanning of the data, in a way that should retain only the critical examples or features, depending on the context, before performing learning on it.  
%Behind the viewpoint selection problem thus lies a feature selection problem, which should rely on a context. 
 \section{Principles}
We consider here a \emph{scene decoding task} where an agent has to estimate its environment state, here called the ``sensory scene'' from sensory samples. The visual scene is organized in objects (or objects parts), whose presence and position is continuously checked by visual inspection. 
Then, decoding a visual scene through saccades consists in identifying the ensemble through the foveation of parts of the scene only. 

We here suppose that a generative model $p$ is given to the agent, that is a probability distribution over $\boldsymbol{z} \in \mathcal{Z}$ (the scene encoding),  $\boldsymbol{u} \in \mathcal{U}$ (the current viewpoint) and $\boldsymbol{x} \in \mathcal{X}$ (the current view), i.e. $\boldsymbol{x}, \boldsymbol{z}, \boldsymbol{u} \sim p(X,Z,U)$.
Stemming from a general POMDP standpoint, important simplifications are considered here, namely (i) \emph{Emitters independence}, that is $p(\boldsymbol{z}, \boldsymbol{u}) = p(\boldsymbol{z})p(\boldsymbol{u})$ so that
any scene can be observed from any viewpoint; 
\emph{(ii) End-effector control}, 
that is the controlled generative process is relatively ``fast'' in comparison with the uncontrolled one
(for, e.g, saccades can be realized in a 100-200 ms interval). 
In consequence the motor command  $\boldsymbol{u}$ is considered as a setpoint (or posture) in the actuator space, that is supposed to be reached 
at short notice once the command is emitted, under classical stability/controllability constraints; \emph{(iii) Uncontrolled environment}, that is the motor command $\boldsymbol{u}$ \emph{is not expected to affect the  latent state $\boldsymbol{z}$},
so that $\boldsymbol{z}$ should depend only on the external dynamics (the external ``uncontrolled'' process); and
\emph{(iv) Static assumption}
i.e. the scene is not changing over time \cite{butko2010infomax}. 
The uncontrolled latent emitter $\boldsymbol{z}$ is thus expected to capture all relevant information about the current scene, while remaining invariant throughout the decoding process.

Each different viewpoint $\boldsymbol{u}$ thus drives a different sensory fields over the same underlying sensory scene, and $\boldsymbol{x}$ (the view) and $\boldsymbol{z}$ (the \emph{latent state}) are now the realization of a generative model parametrized by $\boldsymbol{u}$, i.e.
\begin{align}
\boldsymbol{x}, \boldsymbol{z} | \boldsymbol{u} \sim p(X|Z, \boldsymbol{u}), p(Z)
\end{align}  
Each measure $\boldsymbol{x}$ is generated from a mixed code $(\boldsymbol{z}, \boldsymbol{u})$, with $\boldsymbol{u}$ the controlled part of the code and  $\boldsymbol{z}$ the uncontrolled part. %, so that $p(X,Z,U) = p(X|Z, U) p(X, U)$. 
Note that $\boldsymbol{z}$ is said the latent state out of habit, though both $\boldsymbol{u}$ and $\boldsymbol{z}$ contribute to the generation of $\boldsymbol{x}$.

%The generative model may finally write:
%\begin{align}
%p(X, Z, U) = p(X| Z, U)p(Z) p(U)
%\end{align}
%It should be noted that the dependencies between the three variables can moreover be symetrically decomposed in the form of three conditional models, i.e. :
%\begin{align}
%p(X, Z, U) &= p(X| Z, U) p(Z)p(U)\nonumber\\ 
%&= p(Z| X, U)p(X) p(U)\nonumber\\
%&= p(U|X, Z)p(X) p(Z)\label{eq:three-party}
%\end{align}
%comprising a \emph{forward model} $p(X|\boldsymbol{z}, \boldsymbol{u})$ 
%conditioned on both $\boldsymbol{z}$ and $\boldsymbol{u}$,  an \emph{inverse model} $p(Z|\boldsymbol{x}, \boldsymbol{u})$  conditioned on both on  $\boldsymbol{x}$ and $\boldsymbol{u}$ and an ``\emph{inverse controller}'' $p(U|\boldsymbol{x}, \boldsymbol{z})$ conditioned on both on  $\boldsymbol{x}$ and $\boldsymbol{z}$. This boils down to implementing three variants of a two \emph{degrees of freedom} generative model. 

\paragraph{Variational scene encoding}\label{sec:encoding}


In a model-based approach, the latent variable $\boldsymbol{z}$ is expected to specify the state of the physical environment. In the model-free case, only weak assumptions need to be made about the latent space.  The latent space $\mathcal{Z}$ just needs to be expressive enough to capture and restore all necessary information about the environment.  The \emph{variational encoding} perspective  was originally developed 
to train unsupervised autoencoder neural networks \citep{hinton2006reducing}. The general idea is that an efficient code 
is a code that is both compact and accurate at restoring the data. 
If $\boldsymbol{x}$ is the original data, the corresponding code $\boldsymbol{z}$ is generated by a distribution $q$, i.e. $\boldsymbol{z} \sim q(Z)$. This distribution is called the \emph{encoder}. Then, the reconstruction is made possible with a second conditional probability over the codes, i.e. $p(X|\boldsymbol{z})$, that is called the \emph{decoder}. If $\boldsymbol{z}$ is the current code, the reconstructed data is $\tilde{\boldsymbol{x}} \sim p(X|\boldsymbol{z})$. 
Then, the efficacy of a code is estimated by an information-theoretic quantity, the ``reconstruction cost'' \citep{hinton1994autoencoders} that is defined for every $\boldsymbol{x}$ knowing $p$ and $q$:
\begin{align}
F(\boldsymbol{x};p,q) = - \sum_{\boldsymbol{z} \in \mathcal{Z}} q(\boldsymbol{z}) \log (p(\boldsymbol{x}|\boldsymbol{z})p(\boldsymbol{z})) - H(q)
= \mathbb{E}_{z\sim q} \left[-\log (p(\boldsymbol{x}|\boldsymbol{z})p(\boldsymbol{z}))\right] - H(q)
\label{eq:FEP-energy}
\end{align}
with $\mathcal{Z}$ an arbitrary encoding space, $q$ an arbitrary distribution over the codes, $H(q) = -\sum_z q(\boldsymbol{z}) \log q(\boldsymbol{z})$ the entropy of $q$, $p(X|Z)$ the decoder and $p(Z)$ a prior distribution over the codes.
The densities $p$ and $q$ are called ``variational'' for they can be optimized according to the data \citep{hinton2006fast,kingma2013auto}.  
%$F$ is also called the variational Free Energy for it is mathematically analog to the Helmhotz Free Energy.
It is shown in \cite{kingma2013auto} that an optimal code $q(Z)\simeq p(Z|\boldsymbol{x})$ can be approached through a stochastic gradient descent over $p$ and $q$ according to $-\nabla_{p,q} F(\boldsymbol{x}) $	so that the reconstruction cost should meet the ``description length'' of the data \citep{hinton1994autoencoders}, i.e. its estimated (natural) Shannon Information under the model $p$.
%$
%h(\boldsymbol{x}) \simeq -\log p(\boldsymbol{x}) \simeq  F(\boldsymbol{x})%\simeq - \log \sum_{\boldsymbol{z} \in \mathcal{Z}} p(\boldsymbol{x},\boldsymbol{z})  
%$
%that is a quantity representing how unlikely $\boldsymbol{x}$ is regarding the data model $p$. %Minimizing the cost $F$ according to $p$ and $q$ thus means minimizing the ``surprise'' caused by observing $\boldsymbol{x}$ \cite{friston2010free}.

If we now turn back to the viewpoint selection setup, an additional factor $\boldsymbol{u}$ (the viewpoint) comes into the play. The data $\boldsymbol{x}$ that is actually read is now conditioned on  $\boldsymbol{u}$, so that:
\begin{align}
F(\boldsymbol{x}|\boldsymbol{u};p,q) 
&= \mathbb{E}_{z\sim q} \left[-\log (p(\boldsymbol{x}|\boldsymbol{z},\boldsymbol{u})p(\boldsymbol{z}))\right] - H(q)\\
&= \mathbb{E}_{z\sim q} \left[-\log (p(\boldsymbol{x}|\boldsymbol{z},\boldsymbol{u}))\right] +\text{KL}(q(Z)||p(Z))
\label{eq:FEP-prior-u}\\
&= - \log p(\boldsymbol{x}|\boldsymbol{u}) + \text{KL}(q(Z)||p(Z|\boldsymbol{x}, \boldsymbol{u}))
\label{eq:FEP-posterior-u}\end{align}
with each viewpoint $\boldsymbol{u}$ providing a distinct optimization problem. 

\paragraph{Sequential Bayesian inference}

The chaining of the posterior to the role of the prior in the next inference step is a classical property of sequential Bayesian inference \cite{wald1945sequential}.
When generalized to many observations: $(\boldsymbol{x},\boldsymbol{u}), (\boldsymbol{x}',\boldsymbol{u}')$, ..., $(\boldsymbol{x}^{(n)},\boldsymbol{u}^{(n)})$, the final scene decoding $q^{(n)}(Z)$ writes:
\begin{align}
q^{(n)}(Z) \propto p(\boldsymbol{x}|Z,\boldsymbol{u}) p(\boldsymbol{x}'|Z,\boldsymbol{u}') ... p(\boldsymbol{x}^{(n)}|Z,\boldsymbol{u}^{(n)}) \label{eq:accum}
\end{align}
It is noteworthy that the $\boldsymbol{u}$'s and $\boldsymbol{x}$'s do not need to be stored in the process. At step $n$, only $q^{(n-1)}$ (the current ``belief'') needs to be memorized to estimate $q^{(n)}$, i.e. 
\begin{align} 
q^{(n)}(Z) \propto p(\boldsymbol{x}^{(n)}|Z,\boldsymbol{u}^{(n)}) \times q^{(n-1)}(Z) \label{eq:accum-post}
\end{align}

Finally, from the encoding point of view, the $n^\text{th}$ reconstruction cost $F^{(n)}(\boldsymbol{x}^{(n)}|\boldsymbol{u}^{(n)}, ..., \boldsymbol{x}, \boldsymbol{u})$ also obeys to the chain rule, i.e. is estimated from $q^{(n-1)}$, $\boldsymbol{u}^{(n)}$ and $\boldsymbol{x}^{(n)}$ only:
\begin{align}
F(\boldsymbol{x}^{(n)}|\boldsymbol{u}^{(n)}; q^{(n-1)}, p, q^{(n)}) 
&= \mathbb{E}_{\boldsymbol{z} \sim q^{(n)}} \left[-\log p(\boldsymbol{x}^{(n)}| \boldsymbol{u}^{(n)}, \boldsymbol{z})\right] + \text{KL}(q^{(n)}(Z)||q^{(n-1)}(Z))
\label{eq:FEP-uxun}
\end{align}
%The posterior of a prior step has been passed to the next estimation step and now plays the role of the prior.  This shows that a single distribution $q_\text{\sc post}(Z_{t-1})$ needs to be conserved in memory to calculate the next estimate $q_\text{\sc post}(Z_t)$, i.e.:
with $q^{(n)}$ the shared (or cumulative) encoding according to the past and current observations, and $q^{(n-1)}$ having the role of the prior, providing a \emph{forward} variational encoding scheme (see also \cite{fraccaro2016sequential} for a backward implementation). 


\paragraph{Existing work}

Consider now the \emph{scene decoding task} where an agent has to estimate its environment state $\boldsymbol{z}$ from sampling it from different viewpoints. We here suppose that a generative model  is given to the agent. 
Depending on  the current viewpoint $\boldsymbol{u}$, a different view $\boldsymbol{x}$ is observed at the sensors. So, each different command $\boldsymbol{u}$ provokes a different observation, and thus a different 
estimation of the latent state. It is thus worth to question what is the optimal choice for $\boldsymbol{u}$ in order to maximize the accuracy of the posterior estimate?
That turns  to minimize the number of samples so as to provide an accurate estimate. This approach to inference is called \emph{active sampling} \cite{friston2012perceptions}, for the choice of $\boldsymbol{u}$ determines the sensory sample $\boldsymbol{x}$ that is observed, conditioning the final posterior estimate.

A baseline sampling strategy is to choose $\boldsymbol{u}^{(n)}$ at random and condition the posterior  estimate on this random action. 
More elaborate strategies consider the past observation set
%$\{\boldsymbol{u}^{(1:n-1)}, \boldsymbol{x}^{(1:n-1)}\}$ 
to choose the most promising action $\hat{\boldsymbol{u}}$. %We have seen in  \ref{sec:perception-driven-control} that, under a Markov assumption, the memory of the past context
%at step $n$ .  
Considering the knowledge about past observations absorbed in single posterior distribution $q^{(n-1)}$, the problem turns out to design  a \emph{controller} $C$ which, given a context $q^{(n-1)}$, sets up an action $\boldsymbol{u}^{(n)} = C(q^{(n-1)})$. 
%Here the role of the controller is not to achieve a goal-oriented task, but to render the estimation of the latent state more accurate. The controller is said \emph{perception-driven}. 
%The design of such a controller is not straightforward. 
%On contrary to classical control, there is not definite setpoint $\boldsymbol{z}^*$ to which the controller is supposed to drive the external process (through model inversion for instance). 

The predictive approach to perception-driven control was originally developed by \cite{najemnik2005optimal} to the case of visual search (finding a target feature in an image, i.e. the ``find Waldo'' task).
Given a generative model $p(X,Z,U)$,  the predictive approach relies on predicting an \emph{objective} function $A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)})$ to choose action. 
The objective may tell for instance how good the model is at predicting $\boldsymbol{z}$ (here the target position) when viewing $\boldsymbol{x}$ at position $\boldsymbol{u}$,
knowing $q^{(n-1)}$.
% (the estimated posterior at step $n-1$).
%If the agent has to choose an action $\boldsymbol{u} \in \mathcal{U}$, knowing only $q^{(n-1)}$, 
The optimal action at time $n$ is:
\begin{align*}
\hat{\boldsymbol{u}} = \underset{\boldsymbol{u} \in \mathcal{U}}{\text{ argmax }} \bar{A}(\boldsymbol{u}, q^{(n-1)})
%&= \sum_{z\in\mathcal{Z}} q^{(n-1)}(\boldsymbol{z}) \int_{\mathcal{X}}  A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)}) p(\boldsymbol{x}) d\boldsymbol{x}  
\end{align*}
with $\bar{A}(\boldsymbol{u}, q^{(n-1)})
= \mathbb{E}_{\boldsymbol{z} \sim q^{(n-1)}(Z), \boldsymbol{x} \sim p(X|\boldsymbol{z}, \boldsymbol{u})}\left[A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)})\right]$ the \emph{predicted} objective attached to $\boldsymbol{u}$, 
formally similar to the Value in Reinforcement Learning (i.e. estimate of a future objective)\footnote{It must be noted that in order to render the computations tractable, a sampling approach is generally used to estimate the predicted accuracy, i.e. $\mathbb{E}_p[f(\boldsymbol{x})] \simeq f(\tilde{\boldsymbol{x}})$, with $\tilde{\boldsymbol{x}}\sim p(\boldsymbol{x})$.}.
Many such objective functions are proposed in the literature. They are generally referred as an \emph{intrinsic} motivation \cite{oudeyer2008can} by contrast with the \emph{extrinsic} motivation that relates to the classical rewards in Reinforcement Learning \cite{sutton1998reinforcement}.
The accuracy measure used in the original paper was an ad-hoc one \cite{najemnik2005optimal}, but turned out to be consistent with minimizing the \emph{posterior entropy} \cite{najemnik2009simple}, i.e.:
$A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)}) = -H(q^{(n)}) = \sum_{z \in \mathcal{Z}} q^{(n)}(\boldsymbol{z}) \log q^{(n)}(\boldsymbol{z})$. This approach to optimal visual sampling was further on linked to an ``Infomax'' principle in \cite{butko2010infomax} 
%and shown efficient in artificial visual search using policy gradient \cite{williams1992simple} to learn the controller, with 
taking
\begin{align}A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)}) \equiv I(Z; \boldsymbol{x}|\boldsymbol{u}, q^{(n-1)})
= H(Z|q^{(n-1)}) - H(Z|\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)})
\label{eq:infomax}
\end{align}
with  $H(Z|X, \boldsymbol{u}, q^{(n-1)}) \equiv H(q^{(n)})$.
The Infomax (or posterior entropy minimization) approach generally makes sense for it implicitly relies on the chaining from $q^{(n-1)}$ to $q^{(n)}$, that considers that if $p(\boldsymbol{x}|Z, \boldsymbol{u})$ is consistent with $q^{(n-1)}(Z)$, then the issued posterior entropy should be lower than if $p(\boldsymbol{x}|Z, \boldsymbol{u})$ is at odd with $q^{(n-1)}(Z)$. The model is expected to choose the action that may confirm the initial assumption, though there is no cross-entropy comparison between $q^{(n-1)}$ and $q^{(n)}$.
It is thus potentially vulnerable to model outliers with $q^{(n)}$ having both a low entropy and being inconsistent with $q^{(n-1)}$. 


Another quantity of interest is the so-called \emph{Bayesian surprise} (or \emph{ Salience}) \citep{itti2005bayesian},
% defined as the Kullback-Leibler divergence {\color{blue} between an actual view $(\boldsymbol{x}, \boldsymbol{u})$ and a model $q^{(n-1)}$}.  
%In the original ``bottom-up'' setup, only local statistics $q$ are formed over small image patches of a given image, with $\boldsymbol{u}$ the index of a patch and $q(\boldsymbol{z}|\boldsymbol{x},\boldsymbol{u})$ the features inferred from the data actually observed at $\boldsymbol{u}$. For each patch $\boldsymbol{u}$, the \emph{salience} (or ``\emph{Bayesian surprise}'') of the actual view $\boldsymbol{x}$ given the model is:
%$$ S(\boldsymbol{x},\boldsymbol{u}) = \text{KL}(q(Z| \boldsymbol{x}, \boldsymbol{u})||q(Z))$$
which is a measure of the \emph{in}consistency between a (viewpoint independent)  model $q$ and the data $(\boldsymbol{x}, \boldsymbol{u})$. 
In our sequential setup, the salience writes:
\begin{align}
A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)}) \equiv S(\boldsymbol{x},\boldsymbol{u}, q^{(n-1)}) = \text{KL}(q^{(n)}||q^{(n-1)})
\label{eq:saliency}
\end{align}
%A high salience reports a strong inconsistency with the model ({\color{blue} a high Bayesian surprise}), while a low salience reports a strong consistency with the model ({\color{blue} a low Bayesian surprise}).
%Here, consistent with the PEC alone, 
%with $q^{(n-1)}$ considered as the data model and $q^{(n)}$ the posterior estimated at $(\boldsymbol{x},\boldsymbol{u})$.
%It interestingly shares a formal similarity with the second term of the variational Free Energy (see eq.\ref{eq:FEP-uxun}). 
According to Itti and Baldi, the regions that have a high Bayesian surprise are the ones that attract the sight the most, so that, in a predictive setup, the predicted salience is to be \emph{maximized}.
%The calculation of $S(\boldsymbol{x}, \boldsymbol{z}| \boldsymbol{u})$ at each location $\boldsymbol{u}$ forms a \emph{saliency map} that is then considered as a prediction of where the sight will most likely be attracted (high values most probably attract the sight, low values less probably do). 
%In a sequential setup, a corresponding predictive policy would be:
%$$ \hat{\boldsymbol{u}} = \underset{\boldsymbol{u} \in \mathcal{U}}{\text{ argmax }} \mathbb{E}_{\boldsymbol{z} \sim q^{(n-1)}(Z), \boldsymbol{x} \sim p(X|\boldsymbol{z}, \boldsymbol{u})}\left[\text{KL}(q^{(n)}(Z)||q^{(n-1)}(Z))\right]$$
The saliency model has a strong explanatory power and provides among the best fit with the preferred fixation zones observed in humans.
Its scalability moreover provides straightforward applications in image and video compression  \cite{wang2003foveation,guo2010novel}.
%It  however constitutes a challenge to modelers, for it is at odd with scene interpretation,  
%It thus provides little explanation about the sight-orientation cognitive operations. 
%It is for instance known from eye-tracking data that humans sight is attracted by ``high-level'' features like faces, text or letters \cite{judd2009learning}, that are not captured by the low-level approach. 
%i.e. enters in contradiction 
%(or in ``dialectic'' contrast) 
%with the scene encoding setup, where one objective of the encoder is to minimize the divergence between the inferred code and the prior expectations (see \cite{friston2015active} for a discussion).

At last, the  active inference setup \citep{friston2010free,friston2012perceptions} 
considers the general tendency of the brain to counteract surprising and unpredictable sensory events through minimizing the Free Energy with action, that is  interpreted here as maximizing the ELBO\footnote{Evidence Lower BOund.} through action~:
\begin{align}
A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)}) \equiv -F(\boldsymbol{x}|\boldsymbol{u}; q^{(n-1)}) = 
\log p(\boldsymbol{x}| \boldsymbol{u}; q^{(n-1)}) - \text{KL}(q^{(n-1)}||q^{(n)}))
\label{eq:ELBO}
\end{align}
with $\text{KL}(q^{(n-1)}||q^{(n)}))$ representing the interpretative effort made by interpreting  $\boldsymbol{x}|\boldsymbol{u}$ with $q^{(n)}$ instead of $q^{(n-1)}$. Minimizing $\text{KL}(q^{(n-1)}||q^{(n)}))$ thus corresponds to a \emph{conservative} approach to the scene interpretation
that is \emph{minimally} vulnerable to outliers, i.e. that minimizes the risk of a false interpretation. It is obvious here that the ELBO and the Saliency are antithetic objectives, and no consensus is currently observed in literature about which objective should prevail (though Infomax generally preferred in scene decoding and saliency/surprise preferred in sparse reinforcement learning).





\paragraph{Shared code and information gain}
Following the intuition of \cite{friston2012perceptions}, the scene decoding setup shares a common formalism with the variational encoding setup, at the difference the changing of $F$ now relies on updating the observation set
with a new sample $(\boldsymbol{x}^{(n)}, \boldsymbol{u}^{(n)})$ rather than updating the model parameters.

The structure of the problem (many views on the same scene) implies that the different  views should share a common \emph{information} corresponding to the actual (covered) sensory scene. The sharing of information between two sensory fields $(X, \boldsymbol{u})$ and $(X', \boldsymbol{u}')$ can be quantified by their \emph{mutual information}:
\begin{align}
I((X| \boldsymbol{u}); (X'| \boldsymbol{u}')) &= H(X| \boldsymbol{u}) - H(X| \boldsymbol{u}', X', \boldsymbol{u})\\
&= \mathbb{E}_{X,X'} \left[-\log p(X| \boldsymbol{u}) + \log p(X| \boldsymbol{u}', X', \boldsymbol{u})\right] \nonumber
%&\simeq \mathbb{E}_{X,X'} \left[F(X|\boldsymbol{u}) - F(X'|\boldsymbol{u}', X, \boldsymbol{u})\right] \label{eq:infomax}
\end{align}

with 
($i$) $ p(\boldsymbol{x}| \boldsymbol{u}', \boldsymbol{x}', \boldsymbol{u}) \triangleq \sum_{\boldsymbol{z}} p(\boldsymbol{x}|\boldsymbol{z}, \boldsymbol{u}) p(\boldsymbol{z}|\boldsymbol{x}', \boldsymbol{u}')$ 
the \emph{mutual} likelihood, i.e. the updated likelihood of $\boldsymbol{x}$ at $\boldsymbol{u}$ after seeing $\boldsymbol{x}'$ at $\boldsymbol{u}'$,
%($ii$) $-\log p(\boldsymbol{x}'| \boldsymbol{u}', \boldsymbol{x}, \boldsymbol{u})$
%the \emph{post-sample} approximate natural Shannon Information, 
and ($ii$) 
$-\log p(\boldsymbol{x}| \boldsymbol{u}) + \log p(\boldsymbol{x}| \boldsymbol{u}', \boldsymbol{x}', \boldsymbol{u})$ the 
\emph{information gain} \citep{tishby2011information}.
%We call it here the \emph{conditional Free Energy} (for it is conditioned over $\boldsymbol{x}, \boldsymbol{u}$)
%with: % the post-sample Shannon Information approached by the post-sample Free Energy as: 
An approximation of the information gain, known as the \emph{Compression Improvement} or CI \citep{schmidhuber2007simple,houthooft2016vime}. In our setup, it
writes~:
\begin{align}
\text{CI}(\boldsymbol{x},\boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}') = F(\boldsymbol{x}|\boldsymbol{u};p,q) - F(\boldsymbol{x}|\boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}';p,q') 
\end{align}	
with $F(\boldsymbol{x}|\boldsymbol{u};p,q)$ the pre-sample cost and  
\begin{align}
F(\boldsymbol{x}|\boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}';p,q') &= 
\mathbb{E}_{z\sim q'} \left[-\log (p(\boldsymbol{x}|\boldsymbol{z}, \boldsymbol{u}) p(\boldsymbol{z}|\boldsymbol{x}', \boldsymbol{u}'))\right] +\text{KL}(q'(Z)||p(Z))\label{eq:CI-prior}\\
&= -\log p(\boldsymbol{x}| \boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}') + \text{KL}(q'(Z)||p(Z|\boldsymbol{x}, \boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}'))\label{eq:CI-post}
\end{align}
the \emph{post-sample} cost, with 
\begin{align}
q'(\boldsymbol{z}) \simeq p(\boldsymbol{z}|\boldsymbol{x}, \boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}') = \frac{p(\boldsymbol{x}'|\boldsymbol{z}, \boldsymbol{u}')p(\boldsymbol{z}|\boldsymbol{x}, \boldsymbol{u})}{p(\boldsymbol{x}'|\boldsymbol{u}',\boldsymbol{x},\boldsymbol{u})}
\end{align} 
after optimizing the shared posterior (or shared \emph{code}). From a variational perspective, the passing from $q(Z) \simeq p(Z|\boldsymbol{x}, \boldsymbol{u})$ to $q'(Z) \simeq p(Z|\boldsymbol{x}, \boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}')$ is the \emph{posterior update}.

By subtracting (\ref{eq:CI-prior}) from (\ref{eq:FEP-prior-u}), the CI writes:
\begin{align}
\text{CI}(\boldsymbol{x},\boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}'&;p,q,q')=
  - \mathbb{E}_{z\sim q} \left[\log (p(\boldsymbol{x}|\boldsymbol{z},\boldsymbol{u}))\right] +\text{KL}(q(Z)||p(Z))\nonumber\\
& + \mathbb{E}_{z\sim q'} \left[\log p(\boldsymbol{x}|\boldsymbol{z}, \boldsymbol{u})\right] 
+ \mathbb{E}_{z\sim q'} \left[\log p(\boldsymbol{z}|\boldsymbol{x}', \boldsymbol{u}')\right] -\text{KL}(q'(Z)||p(Z))\label{eq:CI}
\end{align} 
Knowing that $q$ and $q'$ are free parameters, it is tempting to take $q=q'$ to provide a rough CI estimate, that is :
\begin{align}
\tilde{\text{CI}}(\boldsymbol{x},\boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}';p, q) = \mathbb{E}_{z\sim q} \left[\log p(\boldsymbol{z}|\boldsymbol{x}', \boldsymbol{u}')\right]\label{eq:PCI}
\end{align}
that approximates the information gain with the opposite of the cross-entropy cost $\tilde{\text{CI}}(\boldsymbol{x},\boldsymbol{u}, \boldsymbol{x}', \boldsymbol{u}';p, q) = -H(q(Z),p(Z|\boldsymbol{x}', \boldsymbol{u}'))$.
% $H(q(Z), p(Z|\boldsymbol{x}', \boldsymbol{u}'))$ = H(q(Z)) + \text{KL}(q(Z)||p(Z|\boldsymbol{x}', \boldsymbol{u}')$, 
This estimate is maximal at $q(Z) = p(Z|\boldsymbol{x}', \boldsymbol{u}')$. 
Taking instead $q(Z)= p(Z|\boldsymbol{x}, \boldsymbol{u})$ (the pre-sample code), the 
approximate information gain is maximized when $p(Z|\boldsymbol{x}', \boldsymbol{u}')\simeq p(Z|\boldsymbol{x}, \boldsymbol{u})$, i.e. when $p(Z|\boldsymbol{x}', \boldsymbol{u}')$ and $p(Z|\boldsymbol{x}, \boldsymbol{u})$ are highly consistent. If now $\boldsymbol{u}'$ is at choice \emph{before} sampling  $\boldsymbol{x}'$, it is sensible to maximize the predicted CI to maximize the code consistency, i.e.:
\begin{align}
\hat{\boldsymbol{u}}' 
%&= \underset{\upsilon \in \mathcal{U}}{\text{ argmax }} \mathbb{E}_{\boldsymbol{z}\sim q;\boldsymbol{x}'\sim p(X|\boldsymbol{z},\upsilon))} \tilde{\text{CI}}(\boldsymbol{x},\boldsymbol{u}, \boldsymbol{x}',\upsilon;p, q)\nonumber\\
&= \underset{\boldsymbol{u}' \in \mathcal{U}}{\text{ argmax }} \mathbb{E}_{z\sim q; \boldsymbol{x}'\sim p(X|\boldsymbol{z},\boldsymbol{u}'))} 
\left[\log p(\boldsymbol{z}|\boldsymbol{x}', \boldsymbol{u}')\right]
\end{align}
thus providing a general predictive setup to optimize action

In detail, instantiating $q$ with $q^{(n-1)}$ in the sequential setup provides:
\begin{align}A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)}) \equiv \log p(\boldsymbol{z}|\boldsymbol{x}, \boldsymbol{u})\label{eq:LC}
\end{align}
a dramatically simple objective, that will be referred as the \emph{Local Consistency} (LC) objective.
Instantiating $q$ with $q^{(n)}$ gives:
\begin{align}A(\boldsymbol{x}, \boldsymbol{u}, q^{(n-1)}) \equiv 
\mathbb{E}_{z\sim q^{(n)}} \left[\log p(\boldsymbol{z}|\boldsymbol{x}, \boldsymbol{u})\right]\label{eq:PC}
\end{align}
referred as the \emph{Posterior Consistency} (PC) objective.

Generalizing now eqs (\ref{eq:CI-post}) and (\ref{eq:FEP-posterior-u}) to the sequential case (\ref{eq:FEP-uxun}), 
and instantiating $q$ with $q^{(n)}$ in  (\ref{eq:FEP-posterior-u}) $-$ (\ref{eq:CI-post}) gives
	\begin{small}
$
		\tilde{\text{CI}}(\boldsymbol{x},\boldsymbol{u}; q^{(n-1)}) \simeq
		-\log p(\boldsymbol{x}^{(n-1)}| \boldsymbol{u}^{(n-1)}; q^{(n-1)}) 
		+ \text{KL}(q^{(n)}||q^{(n-1)})
		+ \log p(\boldsymbol{x}^{(n-1)}| \boldsymbol{u}^{(n-1)}, \boldsymbol{x}, \boldsymbol{u}; q^{(n-1)}) 
$
	\end{small},
showing that the Saliency objective --~see eq~(\ref{eq:saliency})~-- is the overestimation made \emph{after posterior update} by considering (\ref{eq:PCI}) instead of (\ref{eq:CI}), making it an \emph{oblivious bias} or \emph{optimistic bias} to the scene interpretation that is \emph{maximally} vulnerable to outliers.
Symmetrically, 
instantiating $q$ with $q^{(n-1)}$  allow to interpret the ELBO objective
--~see eq~(\ref{eq:ELBO})~-- as  the underestimation made about the future information gain \emph{before posterior update}, making it the \emph{watchful} or \emph{memory-consistent} bias, that is \emph{minimally} vulnerable to outliers.
Using (\ref{eq:saliency}) or (\ref{eq:ELBO}) as an objective (instead of (\ref{eq:PCI})) is thus expected to \emph{dramatize} the interpretative flaws made by utilizing  (\ref{eq:PCI}) instead of (\ref{eq:CI}), either in an optimistic (\ref{eq:saliency}) or in a conservative (\ref{eq:ELBO}) way. 

\section{Implementation}

\paragraph{Fovea-based computation} 
In superior vertebrates, two principal tricks are used to minimize sensory resource consumption in scene exploration. The first trick is the foveated retina, that concentrates the photoreceptors at the center of the retina, with a more scarce distribution at the periphery. A foveated retina allows both treating central high spatial frequencies, and peripheral low spatial frequencies at a single glance (i.e process several scales in parallel). The second trick is the sequential saccadic scene exploration, already mentioned, that allows to grab high spatial frequency information where it is necessary (serial processing).



\begin{figure}[b!]
	\centerline{
		\hspace{2cm}
		\textbf{a}
		\hspace{4cm}
		\textbf{b}	
		\hspace{3cm}
		\textbf{c}
		\hspace{3cm}
		\textbf{d}
		\hspace{2cm}			
	}
	\centerline{
		\includegraphics[width = \linewidth]{img/ICLR-foveated-model.pdf} 
	}
\centerline{\textbf{e}}	
\centerline{
	\includegraphics[width = \linewidth]{img/NIPS-convolutional.pdf} 
}
	\caption{\textbf{a}--\textbf{c}. Foveal ``pyramidal'' encoding from original image.
	\textbf{d}. Image reconstruction from 60 central coefficients, issuing a 92 \% compression rate.  
	\textbf{e}. Wavelet-based hierarchical CNN encoder.}\label{fig:foveated}
\end{figure}

The baseline vision model we propose relies first on learning local foveated views on images.
%The essential property of foveated images is that they retain high spatial frequency information at the center and keep only low-frequency information at the periphery.  %Foveated image decomposition is rarely proposed in literature for machine learning purposes, at the exception of Simoncelli's group that has developed a framework to process centrally-magnified images in a bio-realistic fashion (see \cite{freeman2011metamers} and \cite{Deza2016piranhas}). 
Consistently with \cite{kortum1996implementation,wang2003foveation}, we restrain here the foveal transformation to its core algorithmic elements, i.e. the local compression of an image according to a particular focus. Our foveal image compression thus rests on a "pyramid" of 2D Haar wavelet coefficients placed at the center of sight. Taking the example of the MNIST database, we first transform the original images according to a 5-levels wavelet decomposition (see figure \ref{fig:foveated}b). We then define a viewpoint $\boldsymbol{u}$ as a set of 3 coordinates $(i,j,h)$, with $i$ the row index, $j$ the column index and $h$ the spatial scale. Each $\boldsymbol{u}$ generates a visual field made of three wavelet coefficients $\boldsymbol{x}_{i,j,h} \in \mathbb{R}^3$, obtained from an horizontal, a vertical and an oblique filter at location $(i,j)$ and scale $h$.  The multiscale visual information $\boldsymbol{x}_{i,j} \in \mathbb{R}^{15}$ available at coordinates $(i,j)$ corresponds to a set of 5 coefficient triplets, namely $\boldsymbol{x}_{i,j}=\{\boldsymbol{x}_{i,j,5}, \boldsymbol{x}_{\lfloor i/2\rfloor,\lfloor j/2\rfloor,4}, \boldsymbol{x}_{\lfloor i/4\rfloor,\lfloor j/4\rfloor,3}, \boldsymbol{x}_{\lfloor i/8\rfloor,\lfloor j/8\rfloor, 2}, \boldsymbol{x}_{\lfloor i/16\rfloor,\lfloor j/16\rfloor, 1}\}$ (see figure \ref{fig:foveated}c), so that each multiscale visual field owns 15 coefficients (as opposed to 784 pixels in the original image).
Fig. \ref{fig:foveated}d displays a reconstructed image from the 4 central viewpoints at coordinates (7, 7), (7, 8) (8, 7) and (8, 8).

A generative model is learned for each $\boldsymbol{u} = (i,j,h)$ (making a total of 266 data models) over the 55,000 examples of the MNIST training set. For each category $\boldsymbol{z}$ and each gaze orientation $\boldsymbol{u}$, a generative model is built over parameter set $\Theta_{\boldsymbol{z},\boldsymbol{u}} = (\rho_{\boldsymbol{z},\boldsymbol{u}}, \boldsymbol{\mu}_{\boldsymbol{z},\boldsymbol{u}}, \boldsymbol{\Sigma}_{\boldsymbol{z},\boldsymbol{u}})$, so that $\forall \boldsymbol{z},\boldsymbol{u}, \tilde{\boldsymbol{x}}_{\boldsymbol{z},\boldsymbol{u}} \sim \mathcal{B}(\rho_{\boldsymbol{z},\boldsymbol{u}}) \times \mathcal{N}(\boldsymbol{\mu}_{\boldsymbol{z},\boldsymbol{u}}, \boldsymbol{\Sigma}_{\boldsymbol{z},\boldsymbol{u}})$ with $\mathcal{B}$ a Bernouilli distribution and $\mathcal{N}$ a multivariate Gaussian. The Bernouilli reports the case where the coefficient triplet is null in the considered portion of the image (which is quite common at high spatial frequencies and/or in the periphery of the image), which results in discarding the corresponding triplet from the Gaussian moments calculation. Each resulting generative model $p(X|\boldsymbol{z},\boldsymbol{u})$ is a mixture of Bernouilli-gated Gaussians over the 10 MNIST labels. 

Two complementary models are used on the encoding side:
($i$) a baseline inference model, with the posterior explicitly calculated using Bayes rule, i.e. $q(Z|\boldsymbol{x},\boldsymbol{u}) = \text{softmax} \log p(\boldsymbol{x}|Z,\boldsymbol{u})$, issuing about 92\% recognition rate on the MNIST test set when combining the 266 models on each wavelet triplet.
($ii$) a convolutional neural network made of five convolution layers corresponding to the five hierarchical levels of the wavelet decomposition (see figure \ref{fig:foveated}e). The CNN is biasless, uses a (2,2) stride for the convolution \emph{without max-pooling}, maximizing \emph{neighbour independence} in the convolutional computational track. The training data is degraded (or compressed) at random, with about 50\% of the wavelet coefficients selected (the others being set at 0).  Without hectic optimization, the network attains a 99\% recognition rate on test set using plain inputs. The cross-entropy loss used in training makes the network output is expected to approach the data log-likelihood, and this is how it is interpreted further on.

\paragraph{Algorithms}

Both the encoder and decoder are thus trained apart for  
%The discriminator and the generator are trained separately in a supervised fashion so that we 
our different objectives can be compared over established models.
Our \emph{model-based} sequential scene decoding algorithm is provided in algorithms \ref{algo:saccade-policy} and \ref{algo:saccade}. 


\begin{algorithm}[t]
	\caption{Prediction-Based Policy}\label{algo:saccade-policy}
	\begin{algorithmic}
		\REQUIRE  $p$ (generator), $q$ (inference), $\rho$ (prior), $\mathcal{U}$ (actions set)
		\STATE predict $z \sim \rho$
		\STATE $\forall u \in \mathcal{U}$, generate $\tilde{\boldsymbol{x}}_u \sim p(\boldsymbol{x}|z,u)$
		%		\RETURN $\tilde{u} = \underset{u \in \mathcal{U}}{\text{argmax }} q(z|\tilde{\boldsymbol{x}}_u,u)$
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
	\caption{Scene Exploration}\label{algo:saccade}
	\begin{algorithmic}
		\REQUIRE  $p$ (generator), $q$ (inference), $\rho_0$ (initial prior), $\mathcal{U}$ (actions set)
		\STATE $\rho \leftarrow \rho_0$ 
		\WHILE {$H(\rho) > H_\text{ref}$}
		\STATE choose: $\tilde{u} \leftarrow \text{Prediction-Based Policy}(p, q, \rho, \mathcal{U})$
		\STATE read: $\boldsymbol{x}_{\tilde{u}}$
		\STATE update: $\forall z, \text{odd}[z] \leftarrow \log q(z|\boldsymbol{x}_{\tilde{u}},\tilde{u}) + \log \rho(z)$ 
		\STATE $\rho \leftarrow \text{softmax} (\text{odd})$ \COMMENT{\emph{the posterior becomes the prior of the next turn}}
		\STATE $\mathcal{U} \leftarrow \mathcal{U} \setminus \{\tilde{u}\}$ 
		\ENDWHILE
		%		\RETURN $\rho$
	\end{algorithmic}
\end{algorithm}

\begin{itemize}
	\item A significant algorithmic add-on when compared with formulas (\ref{eq:step-1}--\ref{eq:step-3}) is the use of a \emph{dynamic actions set} : $\mathcal{U}$. At each turn, the new selected action $\tilde{u}$ is drawn off from $\mathcal{U}$, so that the next choice is made over fresh directions that have not yet been explored. This implements the inhibition of return principle stated in \cite{itti2001computational}.
	\item A second algorithmic aspect is the use of a threshold $H_\text{ref}$ to stop the evidence accumulation process when enough evidence has been gathered. This threshold is a free parameter of the algorithm that sets whether we privilege a conservative (tight) or optimistic (loose) threshold. The stopping criterion needs to be optimized to arbitrate between resource saving and coding accuracy. 
	%is to carefully evaluate the kind of exploratory behavior provided by those principles, and see how they compare with existing active vision algorithms. In practice
\end{itemize}

The saccade exploration algorithm moreover adapts algorithm \ref{algo:saccade} the following way. The process starts from a loose assumption based on reading the root wavelet coefficient of the image, from which an initial guess $\rho_0$ is formed. Then, each follow-up saccade is calculated on the basis of the final coordinates $(i,j) \in [0,..,15]^2$, so that the posterior calculation is based on several coefficient triplets. After selecting $(i,j)$, all the corresponding coordinates $(h,i,j)$ are discarded from $\mathcal{U}$ and can not be reused for upcoming posterior estimation (for the final posterior estimate may be consistent with a uniform scan over the wavelet coefficients). 

\begin{figure}[b!]
	\centerline{
		%\includegraphics[width = .7\linewidth]{img/ICLR-foveated-saccades.png} 
		\includegraphics[width = .2\linewidth]{img/saccade-3-full-traj.png} 
		\includegraphics[width = .2\linewidth]{img/saccade-3-step-1.png} 
		\includegraphics[width = .2\linewidth]{img/saccade-3-step-2.png} 
		\includegraphics[width = .2\linewidth]{img/saccade-3-step-3.png} 
		\includegraphics[width = .2\linewidth]{img/saccade-3-step-4.png}}
	\centerline{\textbf{a} \hspace{2.6cm} \textbf{b} \hspace{2.4cm} \textbf{c} \hspace{2.4cm} \textbf{d} \hspace{2.6cm} \textbf{e}}
	\centerline{\includegraphics[width = .4\linewidth,height=4cm]{img/saccade-3-post.png} 
		\includegraphics[width = .4\linewidth,height=4cm]{img/saccade-3-entropy.png} }
	\vspace{-.2cm}
	\centerline{Read-out steps \hspace{3.6cm} Read-out steps}
	\centerline{\textbf{f} \hspace{5.5cm} \textbf{g}}
	\caption{\textbf{Scene exploration through saccades in the foveated vision model}. \textbf{a}. Saccades trajectory over the original image (initial gaze orientation indicated with a red "plus"). \textbf{b--e}. Progressive image reconstruction over the course of saccades, with \textbf{b}: 5 coefficients triplets + root coefficient (initial gaze orientation), \textbf{c}: 9 coefficients triplets + root coefficient (first saccade), \textbf{d}: 13 coefficients triplets + root coefficient (second saccade), \textbf{e}: 17 coefficients triplets + root coefficient (third saccade) \textbf{f}. Posterior update in function of the number of read-out steps (noting that step 1 stems for the root coefficient and the next steps stem for 3 Haar wavelet coefficients read-out), with one color per category (the numbers over the lines provide the competing labels) \textbf{g}. Posterior entropy update in function of the number of read-out steps.}\label{fig:foveated-saccades}
\end{figure}


An example of such saccadic image exploration is presented in figure \ref{fig:foveated-saccades}\textbf{a} over one MNIST sample.
The state of the recognition process after one saccade is shown on fig. \ref{fig:foveated-saccades}\textbf{b}. The next saccade (fig. \ref{fig:foveated-saccades}\textbf{c})  heads toward a region of the image that is expected to help confirm the guess. The continuing saccade (fig. \ref{fig:foveated-saccades}\textbf{d}) makes a close-by inspection and the final saccade (fig. \ref{fig:foveated-saccades}\textbf{e}) allows to reach the posterior entropy threshold, set at $H_\text{ref} = 1e^{-4}$ here. The second row shows the accumulation of evidence over the coefficients triplets, with fig. \ref{fig:foveated-saccades}\textbf{f} showing the posteriors update of different labels and fig. \ref{fig:foveated-saccades}\textbf{g} showing the posterior entropy update according to the coefficients triplets actually read. Note that several triplets are read for each end-effector position ($i,j$) (see fig. \ref{fig:foveated}c). There is for instance a total of 5 triplets read out at the initial gaze orientation (\textbf{b}), and then 4 triplets read-out for each continuing saccades.

The model provides apparently realistic saccades, for they cover the full range of the image and tend to point over regions that contain class-characteristic pixels. The image reconstruction after 4 saccades allows to visually recognize a "fuzzy" three, while it would not necessarily be the case if the saccades were chosen at random.
The observed trajectory illustrates the \emph{guess confirmation} logic that is behind the active vision framework. Every saccade heads toward a region that is supposed to confirm the current hypothesis. This confirmation bias appears counter-intuitive at first sight, for some would expect the eye to head toward places that may \emph{disprove} the assumption (to challenge the current hypothesis). This is actually not the case for the class-confirming regions are more scarce than the class-disproving regions, so that heading toward a class-confirming region may bring more information in the case it would, by surprise, invalidate the initial assumption.

%{\color{green} With a final posterior approaching $1 - 1e^{-5}$, the model is actually overconfident in its own predictions which introduces a confirmation bias that may harm the final recognition rate. This is not the case in our setup (see next section for quantitative accuracy estimate), but one can not exclude the process to be overconfident at a local minimum. It must be noticed however that the confirmation bias is a more general feature of the active inference framework that should be specifically addressed (with a $T$-horizon forward planning at exponential cost and/or reward-based policy learning -- see \cite{butko2010infomax}). For there is no free lunch, it corresponds to the "price to pay" for reducing the observation range of the image at the risk of potentially neglecting critical covert information. }


\section*{References}
\bibliographystyle{apalike}
\bibliography{biblio}



\end{document}
